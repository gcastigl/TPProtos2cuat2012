
\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

\usepackage{beamerthemesplit}

\usetheme{Warsaw} 

\title{Proxy POP3}
\subtitle{Castiglione, Galindo, Karpovsky}
\author{Protocolos de Comunicación\\ \small ITBA}
\date{Miércoles 31 de Octubre}

\AtBeginSection[]
{
  \begin{frame}{Tabla de contenidos}
    \tableofcontents[currentsection]
  \end{frame}
}


\begin{document}

\frame{\titlepage}

\section[Outline]{}
\frame{\tableofcontents}

\section{Introducción}
\subsection{El problema}
\begin{frame}{El problema}

\par El problema planteado consiste en el análisis de la utilización de algoritmos genéticos para la obtención de pesos optimos para redes neuronales multicapa.\\
\ \\

\par Se estudiarán distintas técnicas de selección, cruza, mutación y reemplazo de los individuos y se detallarán los resultados obtenidos.

\end{frame}

\section{Modelado del problema}
\subsection{Representación de la red neuronal}

\begin{frame}{Representación de la red neuronal}
\par Se representó la red neuronal como una matriz de pesos. \\
\begin{itemize}
\item Cada neurona es una columna de pesos.
\item Cada capa de neuronas es una matriz de pesos.
\item La red neuronal, por consiguiente, es un vector de matrices.
\end{itemize}
\end{frame}

\subsection{Representación de los individuos}

\begin{frame}{Representación de los individuos}
\par Se representó los individuos de la siguiente forma: \\
\begin{itemize}
\item \textbf{Cromosoma:} Arreglo de \textit{floats} que representan los pesos de la red.
\item \textbf{Locus:} Un peso puntual de la red.
\end{itemize}

\par Notar que el \textbf{bias} está representado como una conexión extra a cada una de las neuronas.
\end{frame}

\subsection{Diagramación del algoritmo}

\begin{frame}{Diagramación del algoritmo}
\begin{figure}[H]
\begin{center}
\includegraphics[scale=1.30]{./images/AlgGenModelado.png}
\label{modelado}
\end{center}
\end{figure}

\begin{center}
\par Figura 1: Modelado esquemático con N = 10 y G = 0.6.
\end{center}
\end{frame}

\subsection{Función de fitness}


\begin{frame}{Función de fitness}


\par La función de \textit{fitness} mide el grado de adaptación de un determinado individuo al entorno actual.

\begin{block}{Inversa del ECM}

\[
   f(i) = \frac{1}{ECM}
\]

Siendo:

\begin{itemize}
\item \textbf{i:} Red neuronal (individuo)
\item \textbf{ECM:} Error cuadrático medio obtenido al evaluar la red.
\end{itemize}
\end{block}


\end{frame}


\section{Métodos de selección y reemplazo}

\begin{frame}{Métodos de selección y reemplazo}
\par Los métodos de selección y reemplazo implementados son los siguientes:\\
\begin{itemize}
\item Ruleta
\item Boltzman
\item Elite
\item Universal
\item Mixto
\begin{itemize}
\item Elite + Ruleta
\item Elite + Boltzman
\end{itemize}
\end{itemize}
\end{frame}

\section{Criterios de corte}
\begin{frame}{Criterios de corte}

\par Los criterios de corte implementados son los siguientes:\\

\begin{itemize}
\item \textbf{Máxima cantidad de generaciones:} Dado un número $p$, el algoritmo termina al alcanzarse $p$ generaciones.
\item \textbf{Entorno al óptimo:} Se llega a la solución óptima o se alcanza un fitness superior a una determinada cota.
\end{itemize}
\end{frame}

\begin{frame}{Criterios de corte}
\begin{itemize}
\item \textbf{Contenido:} Se corta al detectar que el mejor fitness de la población no progresa con las generaciones.
\item \textbf{Estructura:} Se finaliza al detectar que una parte relevante de la poblacioón no cambia de generacioón en generación. Es decir, dado un porcentaje $p$, el algoritmo termina cuando la cantidad de individuos iguales de la generación es mayor a dicho $p$.
\end{itemize}
\end{frame}

\section{Mutación y backpropagation}
\begin{frame}{Mutación y backpropagation}

\par Una vez cruzados, los individuos pasan a la siguiente generación con una 
probabilidades bajas e independientes de ser mutados y/o refinados 
mediante el algoritmo de \textit{backpropagation}.\\

\end{frame}

\begin{frame}{Mutación y backpropagation}
Si se considera $p_m$ la probabilidad de que mute un individuo, y $p$ la probabilidad de que mute cada locus, se verifica 
que la probabilidad de que no mute ningún locus es:
\[P(X=0) = p_m(1-p)^{L}+(1-p_m)\]
En otras palabras, equivale a la probabilidad de que el individuo no mute más la probabilidad de que mute pero 
no mute ningún locus. La notación variable probabilística $X$ denota la cantidad de locus mutados. 
También se puede verificar que la probabilidad de que muten exactamente $i$ locus está dada por:
\[P(X=i) = p_mp^i(1-p)^{L-i}comb(L,i)\]
\end{frame}

\begin{frame}{Mutación y backpropagation}
Sin embargo, si se toma $p_m$ y $p$ pequeños, el factor $p_mp^i$ se hace arbitrariamente pequeño, por 
lo que las probabilidades disminuyen drásticamente para valores incrementales de $i$. Se podría incluso 
despreciar la probabilidad de que muten dos locus o más. Dicha probabildid está dada por:
\[P(X\ge 2) = 1 - (P(X=0) + P(X=1))\]
\[P(X\ge 2) = 1 - (p_m(1-p)^{L}+(1-p_m) + p_mp(1-p)^{L-1}L)\]
\[P(X\ge 2) = -p_m(1-p)^{L}+p_m - p_mp(1-p)^{L-1}L)\]
\[P(X\ge 2) = p_m\left(1 - (1-p)^{L} - p(1-p)^{L-1}L)\right)\]
\end{frame}

\begin{frame}{Mutación y backpropagation}
En conclusión, la mutción consiste en agregar cierto ruido a uno de los pesos de la red neuronal en cuestión.
\end{frame}

\begin{frame}{Mutación y backpropagation}
\par Tipos de mutación implementados:
\begin{itemize}
\item \textbf{Mutación clásica:} Se obtiene un número al azar entre $0$ y $1$ menor a 
$p'$ se elige un locus al azar para mutar.
\item \textbf{Mutación no uniforme:} Similar a la mutación clásica, con la salvedad que $p'$ no es constante sino que pasa a ser una función de las generaciones elapsadas: $p'(g) = c^{g}p'_0$

\end{itemize}
\end{frame}


\section{Resultados}

\begin{frame}{Resultados}
\par Se ejecutó el algoritmo con distintos parámetros (mostrados en la siguiente tabla) y la siguiente configuración:\\
\vspace{3px}
\begin{itemize}
\item 30 cromosomas
\item Brecha generacional: $0.5$.
\item 100 Generaciones (criterio de corte)
\item Probabilidad de mutación (clásica): $0.02$.
\item Probabilidad de cruce: $0.4$. Crossover anular.
\item Probabilidad de refinamiento: $0.05$.
\item $k_e = 6$ (para los ejemplos de \textit{Mixed}).
\item Red con dos capas ocultas, ambas de $15$ neuronas.
\item Función de activación tangente hiperbólica.
\end{itemize}
\end{frame}

\begin{frame}{Resultados}

\begin{figure}[H]
\begin{center}
\includegraphics[scale=0.435]{./images/result.png}
\label{modelado}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Resultados}
\par Se puede apreciar que todos los criterios fueron exitosos en minimizar hasta cierto extento el error cuadrático medio de la red, alcanzando al menos 
un error en el orden de $10^{-3}$ en el mejor individuo.
\end{frame}

\begin{frame}{Resultados}
\par Los métodos \textit{Elite} son los más rápidos en converger a menores valores, sin embargo pagan el precio de tener una menor diversidad.\\
\vspace{5px}
Esto es evidente si se compara el error de generalización del mejor individuo con el error de generalización promedio de los individuos, los cuales son particularmente similares.
\end{frame}

\begin{frame}{Resultados}

\par Sin importar qué método se haya utilizado, no se encontraron casos que reduzcan el error a órdenes inferiores a $10^{-4}$, lo cual podría indicar quizás una cota para la arquitectura analizada.\\
\vspace{5px}
\par Por otro lado, se observó que el refinamiento mejoró sustancialmente la efectividad del algoritmo.
\end{frame}


\section{Conclusiones}
\begin{frame}{Conclusiones}
\begin{itemize}
\item No existe un método de selección o reemplazo óptimo. Todos conllevan sus respectivas ventajas o 
desventajas, y la efectividad de cada uno depende de la naturaleza del problema estudiado.
\item Métodos de selección y reemplazo muy elitistas acelera la convergencia inicial a muestras 
con mayor fitness, pero reduce particularmente la diversidad de la población y por lo tanto puede 
caer en mínimos locales. Se consideró que debido a esta limitación el criterio de corte por \textbf{Contenido} resultó muy adecuado para estos casos.
\end{itemize}
\end{frame}

\begin{frame}{Conclusiones}
\begin{itemize}
\item Los criterios que utilizan cierto elitismo junto con algún método que aumente la diversidad de la población traen buenos resultados a largo plazo. Se observó además que dichos métodos son también consistentes a largo plazo, es decir que en sucesivas ejecuciones los resultados son particularmente similares. Esto deja en evidencia, a diferencia de los métodos elititistas que caen fácilmente en mínimos locales, que dicha combinación de métodos conlleva un mejor cubrimiento del dominio.
\end{itemize}
\end{frame}

\begin{frame}{Conclusiones}
\begin{itemize}
\item Si existe la posibilidad de navegar la función de costo utilizando el gradiente, como es el caso de utilizar el algoritmo de \textit{backpropagation}, se puede implementar un refinamiento de la población que mejora sustancialmente el fitness de la población.
\end{itemize}
\end{frame}

\end{document}
